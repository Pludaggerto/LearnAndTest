{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_table(r\"C:\\Users\\lwx\\Dropbox\\SWOT_simulator\\LearnAndTest\\ex02\\train.txt\", \n",
        "                      sep = \" \",\n",
        "                      header = None)\n",
        "\n",
        "test = pd.read_table(r\"C:\\Users\\lwx\\Dropbox\\SWOT_simulator\\LearnAndTest\\ex02\\test.txt\", \n",
        "                      sep = \" \",\n",
        "                      header = None)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "from sklearn.neural_network  import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def cal_accuracy(pre, tru, name):\n",
        "    pre = np.asarray(pre)\n",
        "    tru = np.asarray(tru)\n",
        "    acc = (len(pre) - (np.abs(pre - tru)).sum()) * 100 / len(pre)\n",
        "    info = name + \" accuracy: \" + str(acc) + \"%\"\n",
        "    return acc, info"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "\n",
        "train, test = train_test_split(train, test_size = 0.3)\n",
        "X_train = train[[1,2,3,4]]\n",
        "y_train = train[[0]]\n",
        "X_test = test[[1,2,3,4]]\n",
        "y_test = test[[0]]\n",
        "def training(clf,name):\n",
        "    clf.fit(X_train,y_train)\n",
        "    pre = clf.predict(X_test)\n",
        "    tru = y_test[0]\n",
        "    acc, info = cal_accuracy(pre,tru, name)\n",
        "    return info\n",
        "size = [50, 100, 150]\n",
        "layers = [2, 4, 6]\n",
        "infos = []\n",
        "for i in size:\n",
        "    for j in layers:\n",
        "        hidden_layer_sizes = (i,) * j\n",
        "        clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
        "                     hidden_layer_sizes=hidden_layer_sizes, random_state=1)\n",
        "        name = str(hidden_layer_sizes)\n",
        "        info = training(clf, name)\n",
        "        infos.append(info)\n",
        "        \n",
        "print(infos)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "C:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  warnings.warn(\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\lwx\\anaconda3\\envs\\geos\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['(50, 50) accuracy: 96.91629955947137%', '(50, 50, 50, 50) accuracy: 94.05286343612335%', '(50, 50, 50, 50, 50, 50) accuracy: 95.81497797356828%', '(100, 100) accuracy: 95.59471365638767%', '(100, 100, 100, 100) accuracy: 96.69603524229075%', '(100, 100, 100, 100, 100, 100) accuracy: 95.81497797356828%', '(150, 150) accuracy: 92.29074889867842%', '(150, 150, 150, 150) accuracy: 94.49339207048457%', '(150, 150, 150, 150, 150, 150) accuracy: 96.0352422907489%']"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "batch_size = 64\n",
        "lr = 0.001\n",
        "num_classes = 10\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('mnist_data', train=True, download=True,\n",
        "                               transform=torchvision.transforms.Compose([\n",
        "                                   torchvision.transforms.ToTensor(),\n",
        "                                   torchvision.transforms.Normalize(\n",
        "                                       (0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('mnist_data/', train=False, download=True,\n",
        "                               transform=torchvision.transforms.Compose([\n",
        "                                   torchvision.transforms.ToTensor(),\n",
        "                                   torchvision.transforms.Normalize(\n",
        "                                       (0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size, shuffle=False)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        "import pdb\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNet, self).__init__()\n",
        "        '''第一层卷积，卷积核大小为5*5，步距为1，输入通道为3，输出通道为6'''\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=1)\n",
        "\n",
        "        '''第一层池化层，卷积核为2*2，步距为2，相当于特征图缩小了一半'''\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        '''第二层卷积，卷积核大小为5*5，步距为1，输入通道为6，输出通道为16'''\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "\n",
        "        '''第二层池化层，卷积核为2*2，步距为2，相当于特征图缩小了一半'''\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        '''第一层全连接层，维度由16*5*5=>120'''\n",
        "        self.linear1 = nn.Linear(16 * 4 * 4, 120)\n",
        "\n",
        "        '''第二层全连接层，维度由120=>84'''\n",
        "        self.linear2 = nn.Linear(120, 84)\n",
        "\n",
        "        '''第三层全连接层，维度由64=>10'''\n",
        "        self.linear3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''将数据送入第一个卷积层'''\n",
        "        out = torch.sigmoid(self.conv1(x))\n",
        "\n",
        "        '''将数据送入第一个池化层'''\n",
        "        out = self.pool1(out)\n",
        "\n",
        "        '''将数据送入第二个卷积层'''\n",
        "        out = torch.sigmoid(self.conv2(out))\n",
        "\n",
        "        '''将数据送入第二个池化层'''\n",
        "        out = self.pool2(out)\n",
        "\n",
        "        '''将池化层后的数据进行Flatten，使数据变成能够被FC层接受的Vector'''\n",
        "        pdb.set_trace()\n",
        "        out = out.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        '''将数据送入第一个全连接层'''\n",
        "        out = torch.sigmoid(self.linear1(out))\n",
        "\n",
        "        '''将数据送入第二个全连接层'''\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "\n",
        "        '''将数据送入第三个全连接层得到输出'''\n",
        "        out = self.linear3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "model = LeNet(num_classes)\n",
        "\n",
        "'''设置损失函数'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''设置优化器'''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "'''开始训练'''\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = Variable(images)\n",
        "        labels = Variable(labels)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch + 1, 10, i + 1, total_step, loss.item()))\n",
        "\n",
        "correct = 0  # 预测正确的图片数\n",
        "total = 0  # 总共的图片数\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "    images = Variable(images)\n",
        "    labels = Variable(labels)\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('准确率为: %d %%' % (100 * correct / total))"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        }
      },
      "source": [
        ""
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".NET (C#)",
      "language": "C#",
      "name": ".net-csharp"
    },
    "language_info": {
      "file_extension": ".cs",
      "mimetype": "text/x-csharp",
      "name": "C#",
      "pygments_lexer": "csharp",
      "version": "8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}